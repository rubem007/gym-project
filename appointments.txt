git - Code
Tests
Terraform
Jenkins
Ansible
Kind
ArgoCD

AWS
SonarQube
Trivy

npm run start:dev

npm i --save class-validator class-transformer
npm install prisma --save-dev
npm install prisma @prisma/client
npx prisma init
npm i uuid

Run migration:
    npx prisma migrate dev --name init

Delete all DB and Run migration:
    npx prisma migrate reset

nest new backoffice-api

nest g resource customer --no-spec
nest g class customer/models/dto/create-customer.dto --no-spec
nest g class customer/models/dto/update-customer.dto --no-spec

nest g resource plan --no-spec

nest g s prisma --no-spec
nest g mo prisma --no-spec

npm i --save @nestjs/config
npm i --save @nestjs/axios
npm i @nestjs/swagger
npm i --save class-validator class-transformer
npm install --save @nestjs/passport passport passport-local
npm install --save-dev @types/passport-local
npm install --save @nestjs/jwt passport-jwt
npm install --save-dev @types/passport-jwt
nest g module auth
nest g service auth/auth --no-spec
nest g controller auth/auth --no-spec
nest g service auth/jwt-strategy/jwt-strategy --no-spec
nest g guard auth/auth/jwt
nest g guard auth/roles/role --no-spec
nest g decorator auth/roles/role

npm i @golevelup/nestjs-rabbitmq

nest g module rabbitmq
nest g service rabbitmq --no-spec

nest g controller app

npm install date-fns --save

Entry Point

admin@ventus.com
1root@20

API
nest new api

nest g resource user --no-spec
nest g class user/models/dto/create-user.dto --no-spec
nest g class user/models/dto/update-user.dto --no-spec
nest g decorator auth/roles/roles

Cron job
nest new cron-job-microservice
nest g resource cronJob --no-spec

SMS & Mail
nest new sms-microservice
nest g resource sms
nest g resource mail
nest g resource whatsapp
nest g class mail/models/dto/mail.dto --no-spec
____________________________________________________________
GIT
1ª Vez
git init
git add README.md
git commit -m "add README.md"
git branch -M main
git remote add origin https://github.com/rubem007/gym-project.git
git push -u origin main

Outras vezes
git add . ou git add {nome_arquivo}
git commit -m "mensagem"
git push -u origin main ou caso for na branch insira git push -u origin {nome_branch}

Nova branch
git checkout -b "nome_branch"
git add -A
git commit -m "Create auth feature and added insomnia requests"
git push origin nome_branch

Juntar a branch à main
git checkout main
git merge auth
git push origin main

Deletar uma branch local
git branch -d {nome_branch} 

git pull origin ci

git branch --list
git branch -d ci - elimina a branch localmente
git push origin --delete ci - eliminar branch remota
_____________________________________________________________________________________
AWS commands
  aws configure list
  aws eks --region us-east-1 update-kubeconfig --name fullcycle-cursofc

  aws cloudformation create-stack --stack-name eks-net-gym --template-url https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2020-10-29/amazon-eks-vpc-private-subnets.yaml

  aws cloudformation delete-stack --stack-name eks-net-arch

  aws cloudformation describe-stacks --stack-name eks-net-arch

security group vpc
    eks-net-arch-ControlPlaneSecurityGroup-Ibmh7v7Sy1qT - sg-09f41109affba018d
    default - sg-0cc84d2912e6189b0
EKS SG
    eks-cluster-sg-eks-gym-1680441221 - sg-03bc61b2135d56177
_____________________________________________________________________________________
ssh-keygen -t rsa -b 2048
    C:\Users\Rubem/.ssh/cinemax_key
dir C:\Users\Rubem\.ssh or ls C:/Users/Rubem/.ssh
cat C:/Users/Rubem/.ssh/cinemax_key.pub

dir C:\Users\Rubem\Documents\Cursos\curso-nestjs\gym-api\terraform

terraform init
terraform apply
terraform apply -auto-approve — Apply changes without having to interactively type ‘yes’ to the plan.
terraform fmt - formata o código
terraform plan - mostra o plano de execução
terraform destroy - elimina todos os resources
terraform destroy -target=digitalocean_droplet.jenkins - elimina o resource específico

Access EC2
EC2 API:    ssh ubuntu@54.90.42.60
EC2 DB:     ssh -i ~/.ssh/gym-key-pair ubuntu@10.0.1.59
EC2 Jenkins:     ssh ubuntu@52.3.240.101

Copy file from local host to remote host
    scp ~/.ssh/id_rsa ubuntu@44.200.193.130:/home/ubuntu/.ssh/id_rsa

_____________________________________________________________________________________
Jenkins

Install java
    sudo apt update 
    sudo apt install openjdk-17-jdk
    java --version

Install jenkins
    https://www.jenkins.io/doc/book/installing/linux/
    systemctl status jenkins

Install docker
    https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository
    add jenkins on group docker:
        sudo usermod -aG docker jenkins
        systemctl restart jenkins

Instal kubectl
    sudo apt-get install -y apt-transport-https ca-certificates curl gnupg
    curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
    sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list
    sudo apt-get update
    sudo apt-get install -y kubectl

Access jenkins
    52.3.240.101:8080

Run this command to view the administrator password
    sudo cat /var/lib/jenkins/secrets/initialAdminPassword

Configure pipeline on jenkins
    Add plugins
        docker
        docker pipeline
        kubernetes CLI
        SonarQube Scanner
        Nodejs
    System Configure
        SonarQube servers
            sonar-server
            https://sonarcloud.io/
            sonarqube Jenkins token
    Install Tools -> caso nao esteja a usar o java/maven
        NodeJS
        SonarQubeScanner

A pipeline no jenkins é criada usando a linguagem Groovy
________________________________________________________________________________________________
Ansible

Comandos
ansible localhost -m ping 

ansible all -i '35.168.16.53,' -m ansible.builtin.shell -a "reboot" --private-key=~/.ssh/id_rsa -u ubuntu --become

ansible all -i '3.239.118.82,' -m ping --private-key=~/.ssh/id_rsa -u root

ansible all -i hosts --list-hosts - lista todos os hosts que serão utilizados

ansible all -i hosts -m ping - ping todas as máquinas
ansible ping -i hosts -m ping - ping apenas nas máquinas que pertencem ao grupo ping

ansible all -i hosts -m ping -e "ansible_facts_gathering=false" - ping todas as máquinas

ansible all -i hosts -m reboot - reinicia todas as maquinas
ansible ping -i hosts -m reboot - reinicia as maquinas que estão no grupo ping

ansible-playbook -i hosts playbook.yaml - executa o arquivo yaml playbook

ansible-playbook -i hosts playbook.yaml --ask-become-pass - executa o arquivo yaml playbook. Usa-se quando o remote_user não é o root


ansible-playbook -i hosts install_jenkins.yml install_docker.yml install_kubectl.yml
ansible-playbook -i hosts install_kubectl.yml

Criar user no linux
 useradd rdn007
 usermod -a -G sudo rdn007
 passwd rdn007

Entrar no CLI do container control
docker exec -it control bash

acessar droplet via ssh
ssh -i C:/Users/Rubem/.ssh/cinemax_key root@159.223.149.23

acessar container(ubuntu) via ssh
ssh root@node1

Copiar a chave ssh para outro container(Ubuntu)
ssh-copy-id root@node1

Create a ssh key
ssh-keygen -t rsa -b 2048

Run SSH service
service ssh start

Ansible ad hoc
ssh-agent bash
ssh-add ~/.ssh/id_rsa
________________________________________________________________________________________________
kubectl
    kubectl get all
    kubectl create deploy nginx --image=nginx
    kubectl get po
    kubectl port-forward pod/nginx-676b6c5bbc-kx86j 8181:80
________________________________________________________________________________________________
Sonarqube
    sudo docker run -d --name sonarqube -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true -p 9000:9000 sonarqube:latest
________________________________________________________________________________________________
Trivy
  trivy fs . -> scan the current directory
  trivy repo url-repository -> scan the repository
  trivy fs --scanners misconfig . -> scan the configuration problem (like dockerfile, terraform)
  trivy image gym-app:v1 -> scan the image
  trivy image --scanners vuln rubemnascimento81/gym-app:latest


  sudo docker build -t gym-app:v1 --target production .

  Apos fazer o merge na branch-dev, os logs do trivy(trivy-config-results.sarif) apareceram no code scanning
